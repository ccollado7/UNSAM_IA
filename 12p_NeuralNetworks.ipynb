{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nC18EFXdSqmd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#The stars\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DuLqMAEqS5fa",
    "outputId": "00ce0bd4-c74b-48fe-a10a-606099f07451"
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a-BToGrRTCK1",
    "outputId": "8a4c1beb-29b5-459a-fcbd-5bac2c721f7b"
   },
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "GTr73m2gTDu2",
    "outputId": "11e46b19-d5d6-43db-cc10-f68036941788"
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aoNOblmHX1XY"
   },
   "source": [
    "# Datos: Clasificacion de ropa (Fashion_MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0PMm5jBHq_7a"
   },
   "source": [
    "Asi como sklearn trae utilidades para cargar datasets estandar, keras también trae. En general, keras puede aceptar datasets en forma de Numpy Arrays (como sklearn), pero también trae una clase Dataset que esta optimizada para cargar datos (incluso si son mas grandes que la memoria RAM del equipo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "xiVqgSJhTeXp",
    "outputId": "dfaf44f5-1db9-4ae0-b0b0-ea65d5ff8d49"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uIus71mjtqxf"
   },
   "source": [
    "En Datasets grandes, CrossValidation puede ser muy costoso, por lo cual se recomienda separar un conjunton de validación aparte del training. Esto hacemos a continuación.\n",
    "\n",
    "También normalizamos los píxeles (que van de 0 a 255) para que estén entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7cB3KYyaUnzP"
   },
   "outputs": [],
   "source": [
    "#Separo en entrenamiento y validacion, y normalizo los pixeles\n",
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "I16qmEbDVnsa",
    "outputId": "ac2ff7f3-cc61-46f8-dce4-f318540df518"
   },
   "outputs": [],
   "source": [
    "print(X_train_full.shape)\n",
    "\n",
    "plt.imshow(X_train[0], cmap='binary', interpolation='bicubic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2nY8YQ_0uEPg"
   },
   "source": [
    "Los targets son numericos, del 0 al 9. Podemos guardar las etiquetas asi nos es mas facil analizar que tan bien o mal funciona nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "id": "xNkEq7xEU1YD",
    "outputId": "057d5977-5bc4-47a3-b770-ed4800c275ff"
   },
   "outputs": [],
   "source": [
    "class_names = [\"Remera/top\", \"Pantalones\", \"Pullover\", \"Vestido\", \"Abrigo\",\n",
    "               \"Sandalias\", \"Camisa\", \"Zapatillas\", \"Bolso\", \"Bota\"]\n",
    "\n",
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_staGAxY9yH"
   },
   "source": [
    "# Definir un modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OsfK9opSuPfg"
   },
   "source": [
    "Hay tres formas de definir modelos:\n",
    "* Una es utilizando la clase de ``keras.models.Sequential``, que es apta para modelos donde solamente Layers adyacentes se encuentran conectados entre sí. \n",
    "* Otra es API funcional, que provee mucha mas flexibilidad, ya que se puede construir cualquier clase de red dirigida acíclica. \n",
    "* La ultima forma, es con SubClassing, es decir definiendo nuestras propias clases que hereden de las definidas en Keras, lo cual nos permite extender Keras para nuestras necesidades específicas, aunque no es recomendable a menos que realmente sepamos lo que estamos haciendo.\n",
    "\n",
    "Si bien ahora quizás les sea mas sencillo utilizar la API secuencial, aprender a utilizar la API funcional es casi igual de fácil y provee mas flexibilidad, asi que es la forma que recomiendo de aprender a usar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "36PryIS5X_Oc"
   },
   "source": [
    "## API Secuencial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZXmZK8yXF4u"
   },
   "source": [
    "### Modo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3lSxEA-vSsr"
   },
   "source": [
    "Podemos crear un modelo, e ir añadiendo Layers sobre la marcha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mvgn-wSlYV89"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cnwg1ZjvXLZE"
   },
   "outputs": [],
   "source": [
    "#Creo un modelo secuencial\n",
    "model = keras.models.Sequential()\n",
    "#Y le voy agregando layers\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) #matriz->vector (como np.ravel)\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) #hidden 1\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\")) #hidden 2\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) #output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jojgQMNjYFQu"
   },
   "source": [
    "### Modo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eb17UrHJvTv8"
   },
   "source": [
    "También podemos directamente pasar la lista de Layers al constructor del Modelo ``Sequential``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "63vXIjKCYTOm"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_2k6HdfXlr5"
   },
   "outputs": [],
   "source": [
    "#Sino directamente le paso una lista al crearlo:\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBYZ4zFYYHDG"
   },
   "source": [
    "## API Funcional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0gWy2OctvbZF"
   },
   "source": [
    "La API funcional funciona definiendo Layers y utilizandolo como si fueran \"funciones\" que se aplican a los outputs de otros Layers. Keras irá rastreando estas conecciones, y luego generará un modelo entre el Layer de Inputs, y el de Outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BdBiQp1YXiJ"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-1uPqZmYIeh"
   },
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=[28, 28]) #En este caso es necesario definir el Layer de Inputs\n",
    "flatten = keras.layers.Flatten()(input_)\n",
    "hidden1 = keras.layers.Dense(300, activation=\"relu\")(flatten)\n",
    "hidden2 = keras.layers.Dense(100, activation=\"relu\")(hidden1)\n",
    "output = keras.layers.Dense(10, activation=\"softmax\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9OwGQ8puZJmI"
   },
   "source": [
    "# Compilar y visualizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y1n6UL-ovs4G"
   },
   "source": [
    "Una vez que hemos definido nuestro modelo, es necesario que lo \"compilemos\", entonces Keras creará el gráfico computacional en TensorFlow de acuerdo a como lo hemos definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OVncsjmrZMbz"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zARoy-X0v66Q"
   },
   "source": [
    "Podemos acceder a los diferentes Layers, mediante el atributo ``.layers``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "AaYiz7qVZqSw",
    "outputId": "01674a4a-7186-4ad9-eb61-0cd631a2dec2"
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYy-e7pzwBHz"
   },
   "source": [
    "Y También podemos imprimir un resumen de nuestro modelo, asi como un lindo grafico de el:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "0LXinQM0ZquT",
    "outputId": "c9e379e0-7026-4193-f273-7dd84cee694c"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "colab_type": "code",
    "id": "_HugLm6sZvmx",
    "outputId": "537ac4fb-8984-48f1-9b4e-03a1efa99bc0"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcFeksoHwHbQ"
   },
   "source": [
    "Cada layer tiene atributos a los que podemos acceder, como el nombre, y métodos que nos devuelven, por ejemplo, los pesos.\n",
    "\n",
    "Vemos que por default inicializa los pesos de forma aleatoria entre 0 y 1, y los bias a cero. Esto se puede cambiar pasando un ``initializer=``al compilar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "1Js3Y9CgZ17S",
    "outputId": "015abc71-3978-46cd-d80d-8dcd9689b17b"
   },
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "print(hidden1.name)\n",
    "weights, biases = hidden1.get_weights()\n",
    "print(weights.shape)\n",
    "print(weights[0], biases[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRf0_MB6ZdBX"
   },
   "source": [
    "# Entrenar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jRSYAHruwcjM"
   },
   "source": [
    "Entrenar es tan facil como hacer un ``.fit``, donde podemos especificar muchas cosas como épocas, datos de validación (que evaluará al final de cada época), métricas, etc.\n",
    "\n",
    "El método devuelve un objeto de Historia, con toda la información del entrenamiento (en forma de diccionarios), que podremos utilizar para analizar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "id": "rL9AKbgfZeQe",
    "outputId": "fdfe6454-d036-4855-95a8-f14584d11ed2"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubNbhHnEwwCq"
   },
   "source": [
    "Examinemos el diccionario de parámetros del fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IITIPuw9aATd",
    "outputId": "8adf9a94-93a5-45fd-c8e0-e4a9d5180253"
   },
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rgFx-tzNaGxG",
    "outputId": "291bdd71-8a6a-471e-9d9c-848741885fb5"
   },
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Tg1GkrJw11Y"
   },
   "source": [
    "Podemos usar el atributo \"history\" que nos da un diccionario, para plotear las métricas que usamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "5ksDH-nWaLfX",
    "outputId": "8644fb44-ac33-4aef-cb8a-719d4bc90bd1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6zMsHUuRZgBj"
   },
   "source": [
    "# Evaluar y predecir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d0RQHI_GxEw0"
   },
   "source": [
    "Evaluar en un conjunto de Test, o hacer predicciones, es sumamente fácil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "FYcvFqohZhVv",
    "outputId": "0fdf5824-d365-4039-ccae-8c72a843d2d0"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "6npHqXo7aSUs",
    "outputId": "017d6c3e-746e-4a15-d854-63218cc4d578"
   },
   "outputs": [],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "lysdDpXXaXFY",
    "outputId": "c9cf3a43-402f-4df9-d64c-613735ce876a"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_Ybn92SmonYj",
    "outputId": "e5f70328-795c-46df-e6fe-fdaf8768dd14"
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_proba, axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zVDFbrnOaXN6",
    "outputId": "89b887de-d93e-41e8-c7fa-db20b49aecaf"
   },
   "outputs": [],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "id": "ffbf9KFtadJY",
    "outputId": "fc07ec59-f1be-4098-cfdf-1228bf449177"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[y_test[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DpzyBn70ZigS"
   },
   "source": [
    "# Guardar y Cargar Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S__NXAnsxI_5"
   },
   "source": [
    "Guardar modelos es tan sencillo como hacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDg65TpBZkkH"
   },
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PyTFAQroxL2B"
   },
   "source": [
    "Que luego se puede cargar (por ejemplo en otra computadora, con otro script, para hacer predicciones) usando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oT-6iPoPauFY"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KrejS892xUQ5"
   },
   "source": [
    "También podemos guardar solamente los weights de los layers. Pero en este caso deberemos, antes de cargarlos, definir el mismo modelo que usamos y recien entonces cargar los weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dd0dte83axdC"
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCEBS3enaz0H"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FhizHlVnkjKR"
   },
   "source": [
    "# Regresión: California Housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BdlNX14NxgdO"
   },
   "source": [
    "Veamos como se desempeña para hacer regresión con el dataset de california housing que utilizamos en la guía de ejercicios Datasets. Importamos los datos, y los escaleamos usando StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "8_g1GZM9km8Q",
    "outputId": "760b188a-a326-496f-9687-ee6a99ea0bf3"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EaLKkccNxptl"
   },
   "source": [
    "El modelo que definimos tiene como ultimo layer una funcion lineal, sin ninguna funcion de activación. (Es como hacer regresión lineal, pero fiteando unidades ReLu como funciones de base)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "WFDtfmzxkyls",
    "outputId": "c4b1bb62-c3f3-47df-8d8e-8b38c7d286de"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "ogy8zfnUk9lJ",
    "outputId": "1c8a5e88-ea5d-46ee-f9d4-da9bec5e40cf"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5fQBF1XlAYM"
   },
   "source": [
    "## Ventajas de la API funcional: Modelos no secuenciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GKCoZmChx5rf"
   },
   "source": [
    "Aqui vemos un ejemplo de como podemos usar la API funcional para hacer modelos mas complejos. En el modelo [Wide and Deep](https://https://ai.google/research/pubs/pub45413) se conectan los inputs directamente a los outputs, ademas de pasando por una red profunda de dos capas. De esta manera, el modelo puede aprender features mas abstractos de los datos, y a la vez tomarlos directamente sin distorisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "emM5moUylGFE",
    "outputId": "526593d1-31b6-454f-ed51-bd13f1a6ed74"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "colab_type": "code",
    "id": "lJBY5y7fpWc2",
    "outputId": "3243b481-eaf3-4cd8-f8f2-56e1f6fecac6"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"wide_and_deep_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "AmapksBIlNWA",
    "outputId": "c8eec38d-e067-4fa7-9219-1ce1b8121268"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7hjgiSLzbRo1"
   },
   "source": [
    "# EXTRAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B0UQUJJOyVu0"
   },
   "source": [
    "Callbacks son una manera de hacer cosas durante el entrenamiento. Son utiles en caso que el modelo tarde mucho en fitear. Por ejemplo, podemos guardar el modelo al fin de cada epoca (por si se nos apaga la maquina en el medio del training), o implementar un regularizador EarlyStopping y dejar de fitear si el validation score no mejora, o enviarnos un mail cuando termine el entrenamiento con los resultados, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dW0PRpE-a10X"
   },
   "source": [
    "## Callbacks: Guardar durante entrenamiento (checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JtJ5vPqplluY"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "colab_type": "code",
    "id": "6nY_ql6qa5ph",
    "outputId": "5bb59ed7-8637-4f22-f565-2905a53c9452"
   },
   "outputs": [],
   "source": [
    " checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "\n",
    " history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                     callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o3OtrP40p__9"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "CpZxyWWqqCPQ",
    "outputId": "4af074dc-06ce-40ed-8c6e-f94355f17843"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_valid,y_valid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "03oEvTcQbVcL"
   },
   "source": [
    "## Callbacks: Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWppr7b4lvms"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3bXGXaRbXIt"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BmuTxeNCl6nc"
   },
   "source": [
    "## Sklearn integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5nqSWlNytYA"
   },
   "source": [
    "Y lo mejor de todo, tiene un wrapper que nos permite integrarlo con ScikitLearn. Sklearn lo reconocerá el modelo como uno más de los suyos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "db6zYIGMl5_B"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxMV0o_vmBDG"
   },
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "7vaBNv0-mWV3",
    "outputId": "0a3ed3e5-559b-4473-c068-392f8a6c3076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1726 - val_loss: 2.5859\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6369 - val_loss: 1.3919\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5286 - val_loss: 1.1011\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4911 - val_loss: 1.0702\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4534 - val_loss: 0.5872\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4365 - val_loss: 0.7241\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4228 - val_loss: 0.5997\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4148 - val_loss: 0.9960\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4091 - val_loss: 0.8042\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4049 - val_loss: 1.5251\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4047 - val_loss: 2.5856\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4195 - val_loss: 4.7300\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4333 - val_loss: 2.5087\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4057 - val_loss: 1.6190\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3971 - val_loss: 0.7897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff74062d668>"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=30,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_sHKiYYy7O7"
   },
   "source": [
    "El modelo tiene los métodos usuales de un estimador de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BrpGmS1FmcSC",
    "outputId": "b3546eeb-33ef-4247-e578-1640662c34da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3899\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HUwX9oDNy2HY"
   },
   "source": [
    "Por ejemplo, podemos usarlo para buscar hiperparámetros con RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Mkr2t3Ivmnfz",
    "outputId": "541edafa-1a1d-4393-f44e-68b21d369d28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15 ....\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5557 - val_loss: 1.8752\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3347 - val_loss: 0.9522\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8591 - val_loss: 0.7820\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7360 - val_loss: 0.7249\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6930 - val_loss: 0.6994\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6668 - val_loss: 0.9118\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6514 - val_loss: 0.8495\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6381 - val_loss: 0.8605\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6276 - val_loss: 0.6524\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6125 - val_loss: 0.8619\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6057 - val_loss: 0.8659\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5993 - val_loss: 0.5962\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5859 - val_loss: 0.9062\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5828 - val_loss: 0.9541\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5799 - val_loss: 0.6402\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5706 - val_loss: 0.7806\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5670 - val_loss: 0.7985\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5620 - val_loss: 0.8756\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5585 - val_loss: 0.8958\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5564 - val_loss: 0.8657\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5559 - val_loss: 0.5940\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5476 - val_loss: 0.8007\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5484 - val_loss: 0.7792\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5459 - val_loss: 0.7622\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5453 - val_loss: 0.6476\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5431 - val_loss: 0.5424\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5373 - val_loss: 0.8687\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5424 - val_loss: 0.5390\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5365 - val_loss: 0.7179\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5384 - val_loss: 0.6029\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5362 - val_loss: 0.5947\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5359 - val_loss: 0.5305\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5334 - val_loss: 0.6601\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5341 - val_loss: 0.6326\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5344 - val_loss: 0.5072\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5304 - val_loss: 0.7270\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5341 - val_loss: 0.5055\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5284 - val_loss: 0.7985\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5338 - val_loss: 0.5176\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5305 - val_loss: 0.5823\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5293 - val_loss: 0.7114\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5322 - val_loss: 0.5059\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5302 - val_loss: 0.5008\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5274 - val_loss: 0.7397\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5309 - val_loss: 0.6169\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5303 - val_loss: 0.5264\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5276 - val_loss: 0.6916\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5298 - val_loss: 0.6554\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5290 - val_loss: 0.6607\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5267 - val_loss: 0.8497\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5310 - val_loss: 0.6664\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5294 - val_loss: 0.5996\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5282 - val_loss: 0.6414\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5368\n",
      "[CV]  learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15, total=  30.5s\n",
      "[CV] learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15 ....\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   30.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5605 - val_loss: 23.0855\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4777 - val_loss: 10.8387\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0149 - val_loss: 4.4392\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8729 - val_loss: 1.5338\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8027 - val_loss: 0.7192\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7542 - val_loss: 1.2046\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7160 - val_loss: 2.4524\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6847 - val_loss: 4.1421\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6588 - val_loss: 5.9820\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6371 - val_loss: 7.7654\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6187 - val_loss: 9.6230\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6029 - val_loss: 11.3609\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5896 - val_loss: 12.9821\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5781 - val_loss: 14.2266\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5683 - val_loss: 15.4321\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.9198\n",
      "[CV]  learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15, total=   8.8s\n",
      "[CV] learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.2972 - val_loss: 1.3307\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9648 - val_loss: 0.6934\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6150 - val_loss: 0.5469\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5468 - val_loss: 0.7322\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5372 - val_loss: 0.4963\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5330 - val_loss: 0.5539\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5320 - val_loss: 0.5729\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5297 - val_loss: 0.7873\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5337 - val_loss: 0.5968\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5314 - val_loss: 0.4951\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5286 - val_loss: 0.7591\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5333 - val_loss: 0.5368\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5305 - val_loss: 0.4968\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5305 - val_loss: 0.5778\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5313 - val_loss: 0.5117\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5282 - val_loss: 0.7055\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5320 - val_loss: 0.5399\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5307 - val_loss: 0.5257\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5275 - val_loss: 0.7902\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5327 - val_loss: 0.5852\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5317\n",
      "[CV]  learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15, total=  11.7s\n",
      "[CV] learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4256 - val_loss: 66.5657\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9941 - val_loss: 137.1490\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2587 - val_loss: 716.1611\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.3545 - val_loss: 2297.8604\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 17.0750 - val_loss: 9988.3398\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 198.7058 - val_loss: 39231.9727\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 424.9947 - val_loss: 155196.9219\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2992.7771 - val_loss: 612492.9375\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 7662.3345 - val_loss: 2435756.2500\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 53693.9375 - val_loss: 10128962.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 135637.9062 - val_loss: 39694520.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 105477.4922\n",
      "[CV]  learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21, total=   6.6s\n",
      "[CV] learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1573 - val_loss: 23.1193\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5349 - val_loss: 22.1675\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5192 - val_loss: 22.3752\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5148 - val_loss: 21.3891\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5108 - val_loss: 20.8855\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5082 - val_loss: 20.6379\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5070 - val_loss: 20.0736\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5050 - val_loss: 20.7178\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5029 - val_loss: 20.0844\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5032 - val_loss: 17.0622\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5036 - val_loss: 19.1666\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5017 - val_loss: 20.8246\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5023 - val_loss: 22.0298\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5049 - val_loss: 17.6022\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5024 - val_loss: 18.6171\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5024 - val_loss: 20.0451\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5005 - val_loss: 17.5898\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5040 - val_loss: 17.4526\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5012 - val_loss: 19.5015\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5011 - val_loss: 17.3223\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.9327\n",
      "[CV]  learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21, total=  11.6s\n",
      "[CV] learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4616 - val_loss: 0.5742\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6113 - val_loss: 6.7367\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5784 - val_loss: 6.5227\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5820 - val_loss: 19.7082\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6738 - val_loss: 205.7214\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6846 - val_loss: 282.6046\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.5718 - val_loss: 656.3253\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 12.3829 - val_loss: 1380.0121\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 14.8443 - val_loss: 2817.4539\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 7.4320 - val_loss: 4499.3813\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 121.3308 - val_loss: 8457.8711\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 11.0521\n",
      "[CV]  learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21, total=   6.6s\n",
      "[CV] learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.5089 - val_loss: 2.6033\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0793 - val_loss: 1.0424\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8038 - val_loss: 0.7507\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7203 - val_loss: 0.6758\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6785 - val_loss: 0.6484\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6498 - val_loss: 0.6241\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6261 - val_loss: 0.6073\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6055 - val_loss: 0.5826\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5870 - val_loss: 0.5597\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5700 - val_loss: 0.5445\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5547 - val_loss: 0.5314\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5408 - val_loss: 0.5147\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5278 - val_loss: 0.5030\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5159 - val_loss: 0.4904\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5051 - val_loss: 0.4791\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4948 - val_loss: 0.4695\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4857 - val_loss: 0.4608\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4772 - val_loss: 0.4524\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4691 - val_loss: 0.4476\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4621 - val_loss: 0.4383\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4555 - val_loss: 0.4355\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4494 - val_loss: 0.4282\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4437 - val_loss: 0.4230\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4384 - val_loss: 0.4166\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4339 - val_loss: 0.4161\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4294 - val_loss: 0.4142\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4254 - val_loss: 0.4100\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4217 - val_loss: 0.4132\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4180 - val_loss: 0.4103\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4149 - val_loss: 0.4032\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4118 - val_loss: 0.3964\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4089 - val_loss: 0.3956\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4062 - val_loss: 0.4013\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4035 - val_loss: 0.4004\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4012 - val_loss: 0.3913\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3988 - val_loss: 0.3986\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3968 - val_loss: 0.3871\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3946 - val_loss: 0.3998\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3927 - val_loss: 0.3858\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3908 - val_loss: 0.3967\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3890 - val_loss: 0.3918\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3873 - val_loss: 0.3866\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3858 - val_loss: 0.3800\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3840 - val_loss: 0.3997\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3827 - val_loss: 0.3861\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3811 - val_loss: 0.3805\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3799 - val_loss: 0.3919\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3785 - val_loss: 0.3826\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3772 - val_loss: 0.3812\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3759 - val_loss: 0.3905\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3746 - val_loss: 0.3832\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3737 - val_loss: 0.3827\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3725 - val_loss: 0.3859\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3865\n",
      "[CV]  learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87, total=  32.3s\n",
      "[CV] learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.7762 - val_loss: 17.5435\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1017 - val_loss: 15.4502\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8039 - val_loss: 11.1084\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7051 - val_loss: 8.0885\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6575 - val_loss: 6.1076\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6260 - val_loss: 4.7302\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6007 - val_loss: 3.6783\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5790 - val_loss: 2.8274\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5600 - val_loss: 2.2526\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5433 - val_loss: 1.7966\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5284 - val_loss: 1.4646\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5153 - val_loss: 1.1656\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5036 - val_loss: 0.9599\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4932 - val_loss: 0.8400\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4839 - val_loss: 0.7148\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4756 - val_loss: 0.6408\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4680 - val_loss: 0.5679\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4612 - val_loss: 0.5264\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4549 - val_loss: 0.4894\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4493 - val_loss: 0.4711\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4442 - val_loss: 0.4525\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4395 - val_loss: 0.4467\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4352 - val_loss: 0.4404\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4313 - val_loss: 0.4333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4276 - val_loss: 0.4303\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4242 - val_loss: 0.4284\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4209 - val_loss: 0.4270\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4180 - val_loss: 0.4269\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4148 - val_loss: 0.4416\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4127 - val_loss: 0.4363\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4099 - val_loss: 0.4330\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4074 - val_loss: 0.4407\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.4484\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4029 - val_loss: 0.4646\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4009 - val_loss: 0.4789\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3989 - val_loss: 0.4745\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3970 - val_loss: 0.4974\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.5135\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4088\n",
      "[CV]  learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87, total=  23.3s\n",
      "[CV] learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.8501 - val_loss: 2.0961\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1187 - val_loss: 1.2079\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8431 - val_loss: 0.8075\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7630 - val_loss: 0.7207\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7220 - val_loss: 0.6952\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6925 - val_loss: 0.6614\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6677 - val_loss: 0.6378\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6461 - val_loss: 0.6132\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6268 - val_loss: 0.6043\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6081 - val_loss: 0.5937\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5908 - val_loss: 0.5658\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5749 - val_loss: 0.5551\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5601 - val_loss: 0.5476\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5465 - val_loss: 0.5450\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5340 - val_loss: 0.5314\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5225 - val_loss: 0.5067\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5119 - val_loss: 0.4983\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5020 - val_loss: 0.4873\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4930 - val_loss: 0.4748\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4849 - val_loss: 0.4767\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4771 - val_loss: 0.4719\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4701 - val_loss: 0.4623\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4637 - val_loss: 0.4640\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4575 - val_loss: 0.4777\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4521 - val_loss: 0.4488\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4469 - val_loss: 0.4475\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4423 - val_loss: 0.4420\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4378 - val_loss: 0.4449\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4337 - val_loss: 0.4581\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4301 - val_loss: 0.4385\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4265 - val_loss: 0.4226\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4233 - val_loss: 0.4458\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4201 - val_loss: 0.4242\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4174 - val_loss: 0.4542\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4149 - val_loss: 0.4279\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4122 - val_loss: 0.4341\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4101 - val_loss: 0.4189\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4344\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4056 - val_loss: 0.4235\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.4183\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4015 - val_loss: 0.4552\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4001 - val_loss: 0.4411\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3981 - val_loss: 0.4073\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3967 - val_loss: 0.4294\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.4238\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3936 - val_loss: 0.4128\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3921 - val_loss: 0.3977\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3909 - val_loss: 0.4028\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3893 - val_loss: 0.4362\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3884 - val_loss: 0.4235\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3870 - val_loss: 0.4171\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3859 - val_loss: 0.4273\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3849 - val_loss: 0.4076\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3839 - val_loss: 0.3885\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3827 - val_loss: 0.4003\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3816 - val_loss: 0.4176\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.4201\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3799 - val_loss: 0.4177\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3789 - val_loss: 0.4166\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3779 - val_loss: 0.3910\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3772 - val_loss: 0.4094\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3763 - val_loss: 0.4364\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3757 - val_loss: 0.4025\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3749 - val_loss: 0.4028\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3737\n",
      "[CV]  learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87, total=  39.4s\n",
      "[CV] learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.4720 - val_loss: 7.9723\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1323 - val_loss: 5.6563\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8832 - val_loss: 4.1443\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8066 - val_loss: 3.1169\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7657 - val_loss: 2.6199\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7374 - val_loss: 2.2830\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7171 - val_loss: 1.9726\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6983 - val_loss: 1.7536\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6816 - val_loss: 1.5653\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6663 - val_loss: 1.4316\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6521 - val_loss: 1.3165\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6387 - val_loss: 1.2101\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6261 - val_loss: 1.1236\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6139 - val_loss: 1.0591\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6024 - val_loss: 0.9875\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5910 - val_loss: 0.9345\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5804 - val_loss: 0.8832\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5701 - val_loss: 0.8424\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5602 - val_loss: 0.8079\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5511 - val_loss: 0.7646\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5420 - val_loss: 0.7347\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5332 - val_loss: 0.7075\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5249 - val_loss: 0.6815\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5165 - val_loss: 0.6537\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5095 - val_loss: 0.6361\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5020 - val_loss: 0.6174\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4952 - val_loss: 0.6011\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4887 - val_loss: 0.5887\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4824 - val_loss: 0.5778\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4766 - val_loss: 0.5671\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4710 - val_loss: 0.5557\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4658 - val_loss: 0.5475\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4608 - val_loss: 0.5403\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4561 - val_loss: 0.5322\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4516 - val_loss: 0.5250\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4476 - val_loss: 0.5165\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4436 - val_loss: 0.5106\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4400 - val_loss: 0.5053\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4364 - val_loss: 0.5004\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4333 - val_loss: 0.4966\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4302 - val_loss: 0.4922\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4274 - val_loss: 0.4891\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4248 - val_loss: 0.4850\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4220 - val_loss: 0.4854\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4198 - val_loss: 0.4828\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4173 - val_loss: 0.4779\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4153 - val_loss: 0.4783\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4131 - val_loss: 0.4755\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4111 - val_loss: 0.4765\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4093 - val_loss: 0.4753\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4714\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4060 - val_loss: 0.4726\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4721\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4027 - val_loss: 0.4708\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4009 - val_loss: 0.4703\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3998 - val_loss: 0.4713\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3985 - val_loss: 0.4704\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3970 - val_loss: 0.4718\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3958 - val_loss: 0.4712\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3944 - val_loss: 0.4701\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3936 - val_loss: 0.4718\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3924 - val_loss: 0.4716\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3913 - val_loss: 0.4704\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3903 - val_loss: 0.4735\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3892 - val_loss: 0.4738\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3884 - val_loss: 0.4729\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3873 - val_loss: 0.4716\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3864 - val_loss: 0.4731\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3855 - val_loss: 0.4720\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3846 - val_loss: 0.4721\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4001\n",
      "[CV]  learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24, total=  43.2s\n",
      "[CV] learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.7641 - val_loss: 28.0492\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.0504 - val_loss: 43.0472\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6124 - val_loss: 37.0128\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3603 - val_loss: 28.7538\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1689 - val_loss: 20.6120\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0259 - val_loss: 14.6245\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9261 - val_loss: 10.5960\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8594 - val_loss: 7.2861\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8137 - val_loss: 5.1836\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7810 - val_loss: 3.7344\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7555 - val_loss: 2.7778\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7346 - val_loss: 1.9391\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7165 - val_loss: 1.4673\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7002 - val_loss: 1.2321\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6852 - val_loss: 0.9812\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6712 - val_loss: 0.8534\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6583 - val_loss: 0.7166\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6459 - val_loss: 0.6424\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6340 - val_loss: 0.5949\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6226 - val_loss: 0.5764\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6116 - val_loss: 0.5809\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6010 - val_loss: 0.6027\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5911 - val_loss: 0.6369\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5816 - val_loss: 0.6922\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5725 - val_loss: 0.7604\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5639 - val_loss: 0.8304\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5555 - val_loss: 0.8810\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5477 - val_loss: 0.9624\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5401 - val_loss: 0.9578\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5332 - val_loss: 1.0158\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5490\n",
      "[CV]  learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24, total=  18.6s\n",
      "[CV] learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.9218 - val_loss: 4.3285\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2869 - val_loss: 2.8653\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9733 - val_loss: 1.8260\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8526 - val_loss: 1.2974\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7870 - val_loss: 0.9606\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7448 - val_loss: 0.7924\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7141 - val_loss: 0.7158\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6902 - val_loss: 0.6616\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6699 - val_loss: 0.6363\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6525 - val_loss: 0.6160\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6364 - val_loss: 0.5999\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6216 - val_loss: 0.5855\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6084 - val_loss: 0.5729\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5959 - val_loss: 0.5615\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5844 - val_loss: 0.5509\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5739 - val_loss: 0.5399\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5641 - val_loss: 0.5301\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5547 - val_loss: 0.5210\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5461 - val_loss: 0.5129\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5381 - val_loss: 0.5062\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5305 - val_loss: 0.4992\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5234 - val_loss: 0.4932\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5169 - val_loss: 0.4875\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5106 - val_loss: 0.4857\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5050 - val_loss: 0.4783\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4996 - val_loss: 0.4746\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4945 - val_loss: 0.4700\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4897 - val_loss: 0.4676\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4851 - val_loss: 0.4687\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4810 - val_loss: 0.4618\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4771 - val_loss: 0.4607\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4732 - val_loss: 0.4630\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4697 - val_loss: 0.4583\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4663 - val_loss: 0.4643\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4633 - val_loss: 0.4591\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4603 - val_loss: 0.4562\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4576 - val_loss: 0.4539\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4550 - val_loss: 0.4547\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4525 - val_loss: 0.4534\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4502 - val_loss: 0.4523\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4478 - val_loss: 0.4613\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4460 - val_loss: 0.4593\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4438 - val_loss: 0.4497\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4420 - val_loss: 0.4544\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4402 - val_loss: 0.4533\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4383 - val_loss: 0.4497\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4367 - val_loss: 0.4470\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4352 - val_loss: 0.4470\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4336 - val_loss: 0.4532\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4322 - val_loss: 0.4549\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4307 - val_loss: 0.4534\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4295 - val_loss: 0.4593\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4281 - val_loss: 0.4535\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4269 - val_loss: 0.4484\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4255 - val_loss: 0.4489\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4244 - val_loss: 0.4465\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4232 - val_loss: 0.4489\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4221 - val_loss: 0.4514\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4209 - val_loss: 0.4499\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4198 - val_loss: 0.4441\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4188 - val_loss: 0.4476\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4178 - val_loss: 0.4501\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.4431\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4160 - val_loss: 0.4385\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4151 - val_loss: 0.4381\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4440\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4134 - val_loss: 0.4354\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4126 - val_loss: 0.4381\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4117 - val_loss: 0.4341\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4109 - val_loss: 0.4395\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4101 - val_loss: 0.4340\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4094 - val_loss: 0.4407\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4084 - val_loss: 0.4309\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4328\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4071 - val_loss: 0.4349\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4063 - val_loss: 0.4346\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4056 - val_loss: 0.4339\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.4333\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4042 - val_loss: 0.4281\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4035 - val_loss: 0.4354\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4322\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4022 - val_loss: 0.4299\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4015 - val_loss: 0.4292\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4008 - val_loss: 0.4341\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4000 - val_loss: 0.4219\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3995 - val_loss: 0.4290\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3987 - val_loss: 0.4329\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3982 - val_loss: 0.4306\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3975 - val_loss: 0.4337\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3968 - val_loss: 0.4250\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3962 - val_loss: 0.4237\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3957 - val_loss: 0.4191\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.4238\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3943 - val_loss: 0.4203\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3937 - val_loss: 0.4209\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3932 - val_loss: 0.4215\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3926 - val_loss: 0.4250\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3920 - val_loss: 0.4160\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3915 - val_loss: 0.4199\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3910 - val_loss: 0.4242\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3897\n",
      "[CV]  learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24, total= 1.0min\n",
      "[CV] learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2 .....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1013 - val_loss: 5.2312\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8603 - val_loss: 26.5013\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7494 - val_loss: 40.6122\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0991 - val_loss: 135.6917\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3388 - val_loss: 237.1149\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.6734 - val_loss: 506.5568\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.0735 - val_loss: 1165.5585\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 19.0953 - val_loss: 2646.9744\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 28.1002 - val_loss: 5780.9751\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 97.2630 - val_loss: 13751.4141\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 159.4888 - val_loss: 31633.9141\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 81.5957\n",
      "[CV]  learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2, total=   6.5s\n",
      "[CV] learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2 .....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4769 - val_loss: 14.0701\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5769 - val_loss: 16.8410\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5493 - val_loss: 19.0635\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5365 - val_loss: 19.7342\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5272 - val_loss: 20.0593\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5202 - val_loss: 20.2376\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5153 - val_loss: 20.0296\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5113 - val_loss: 20.3793\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5078 - val_loss: 20.1103\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5063 - val_loss: 18.4892\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5056 - val_loss: 19.4013\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.9640\n",
      "[CV]  learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2, total=   6.3s\n",
      "[CV] learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2 .....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.0333 - val_loss: 13.7380\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6240 - val_loss: 10.0594\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7131 - val_loss: 41.2693\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1121 - val_loss: 74.9048\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9784 - val_loss: 205.5686\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9726 - val_loss: 246.7374\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.5115 - val_loss: 388.8353\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.9673 - val_loss: 620.5347\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 6.9990 - val_loss: 919.7248\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.1843 - val_loss: 1082.5530\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 21.4948 - val_loss: 1471.0371\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 10.2613 - val_loss: 1957.3098\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.0491\n",
      "[CV]  learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2, total=   6.8s\n",
      "[CV] learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2457 - val_loss: 22.8634\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1255 - val_loss: 36.5661\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9314 - val_loss: 304.7440\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8113 - val_loss: 71.4703\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8365 - val_loss: 312.6019\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.8876 - val_loss: 0.4035\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4331 - val_loss: 0.3815\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3841 - val_loss: 0.3614\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3771 - val_loss: 0.3613\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3676 - val_loss: 0.3455\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.3469\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3623 - val_loss: 0.3554\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 0.3456\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3603 - val_loss: 0.3430\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3515 - val_loss: 0.3427\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3531 - val_loss: 0.3421\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3472 - val_loss: 0.3402\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3515 - val_loss: 0.3426\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.3416\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3443 - val_loss: 0.3385\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3428\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3416 - val_loss: 0.3400\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.3584\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3413 - val_loss: 0.3509\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3375 - val_loss: 0.3590\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3367 - val_loss: 0.3456\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3369 - val_loss: 0.3546\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3367 - val_loss: 0.3542\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3350 - val_loss: 0.3522\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3347 - val_loss: 0.3408\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3580\n",
      "[CV]  learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38, total=  17.2s\n",
      "[CV] learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8950 - val_loss: 3.0949\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5223 - val_loss: 0.4712\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4610 - val_loss: 0.4231\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4356 - val_loss: 0.4021\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4204 - val_loss: 0.4323\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4116 - val_loss: 0.6513\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4057 - val_loss: 0.8508\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4000 - val_loss: 1.0201\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3954 - val_loss: 1.1757\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3924 - val_loss: 0.8698\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3877 - val_loss: 0.9377\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3839 - val_loss: 1.0793\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3820 - val_loss: 1.1923\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3805 - val_loss: 1.1186\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4037\n",
      "[CV]  learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38, total=   8.2s\n",
      "[CV] learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9047 - val_loss: 1.2874\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4870 - val_loss: 0.7809\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4394 - val_loss: 1.8555\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5436 - val_loss: 18.7096\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5247 - val_loss: 78.6921\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8047 - val_loss: 0.4362\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4359 - val_loss: 0.3913\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4187 - val_loss: 0.4218\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4075 - val_loss: 0.4237\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4053 - val_loss: 0.3656\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3912 - val_loss: 0.4488\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3900 - val_loss: 0.3706\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3853 - val_loss: 0.3624\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3828 - val_loss: 0.4259\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3798 - val_loss: 0.3565\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3770 - val_loss: 0.4250\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.3505\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3754 - val_loss: 0.3618\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3701 - val_loss: 0.4284\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3671 - val_loss: 0.3457\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3717 - val_loss: 0.3816\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3663 - val_loss: 0.3408\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3623 - val_loss: 0.3554\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3605 - val_loss: 0.4284\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3601 - val_loss: 0.3360\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3578 - val_loss: 0.3477\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3585 - val_loss: 0.4174\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3566 - val_loss: 0.3349\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3770 - val_loss: 0.3633\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3712 - val_loss: 0.3616\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3517 - val_loss: 0.3402\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3498 - val_loss: 0.5020\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3503 - val_loss: 0.3499\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3469 - val_loss: 0.4519\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3493 - val_loss: 0.3287\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3454 - val_loss: 0.3331\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3439 - val_loss: 0.3294\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3450 - val_loss: 0.3655\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3467 - val_loss: 0.3218\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3438 - val_loss: 0.3303\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3385 - val_loss: 0.5673\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.3217\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3429 - val_loss: 0.3217\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3382 - val_loss: 0.4038\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3380 - val_loss: 0.3215\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3421 - val_loss: 0.3412\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3340 - val_loss: 0.3164\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3380 - val_loss: 0.3534\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3435 - val_loss: 0.4147\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3366 - val_loss: 0.3573\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3308 - val_loss: 0.6192\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3347 - val_loss: 0.3145\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3320 - val_loss: 0.3750\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3379 - val_loss: 0.3377\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.3759\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3360 - val_loss: 0.3173\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3368 - val_loss: 0.4066\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3314 - val_loss: 0.3240\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3258 - val_loss: 0.3834\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3292 - val_loss: 0.3099\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3337 - val_loss: 0.3125\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3247 - val_loss: 0.3955\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3258 - val_loss: 0.3104\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3248 - val_loss: 0.3076\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3286 - val_loss: 0.3414\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3358 - val_loss: 0.3519\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3301 - val_loss: 0.3122\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3304 - val_loss: 0.3076\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3199 - val_loss: 0.3483\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3200 - val_loss: 0.3423\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3249 - val_loss: 0.3039\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3222 - val_loss: 0.3567\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3286 - val_loss: 0.3128\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3257 - val_loss: 0.3098\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3196 - val_loss: 0.4064\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3401 - val_loss: 0.5664\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3276 - val_loss: 0.3067\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3194 - val_loss: 0.3687\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3168 - val_loss: 0.3029\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3189 - val_loss: 0.3284\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3173 - val_loss: 0.3047\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3164 - val_loss: 0.3430\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3163 - val_loss: 0.3166\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3254 - val_loss: 0.4271\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.3018\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3144 - val_loss: 0.3009\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3207 - val_loss: 0.3235\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3148 - val_loss: 0.3020\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3121 - val_loss: 0.3878\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3145 - val_loss: 0.3008\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3169 - val_loss: 0.3182\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3136 - val_loss: 0.3004\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3124 - val_loss: 0.3284\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3119 - val_loss: 0.4480\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3103 - val_loss: 0.3328\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3099 - val_loss: 0.4776\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3454 - val_loss: 0.3339\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3186 - val_loss: 0.3280\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3124 - val_loss: 0.5406\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3114 - val_loss: 0.3038\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3124\n",
      "[CV]  learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38, total=  56.4s\n",
      "[CV] learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21 ..\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.0446 - val_loss: 7.0502\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3108 - val_loss: 7.2037\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6259 - val_loss: 5.5884\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3383 - val_loss: 3.7640\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1769 - val_loss: 2.5552\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0669 - val_loss: 2.0914\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9873 - val_loss: 1.6989\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9225 - val_loss: 1.4173\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8695 - val_loss: 1.2066\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8251 - val_loss: 1.0479\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7880 - val_loss: 0.9248\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7571 - val_loss: 0.8264\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7314 - val_loss: 0.7581\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7096 - val_loss: 0.7119\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6917 - val_loss: 0.6743\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6760 - val_loss: 0.6514\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6629 - val_loss: 0.6371\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6514 - val_loss: 0.6283\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6412 - val_loss: 0.6229\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6322 - val_loss: 0.6221\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6241 - val_loss: 0.6180\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6164 - val_loss: 0.6178\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6092 - val_loss: 0.6150\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6023 - val_loss: 0.6175\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5962 - val_loss: 0.6112\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5900 - val_loss: 0.6049\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5840 - val_loss: 0.6013\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5783 - val_loss: 0.5932\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5726 - val_loss: 0.5873\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5672 - val_loss: 0.5832\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5619 - val_loss: 0.5789\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5568 - val_loss: 0.5713\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5516 - val_loss: 0.5664\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5467 - val_loss: 0.5613\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5418 - val_loss: 0.5537\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5371 - val_loss: 0.5535\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5326 - val_loss: 0.5419\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5281 - val_loss: 0.5418\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5237 - val_loss: 0.5343\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5195 - val_loss: 0.5282\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5153 - val_loss: 0.5252\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5113 - val_loss: 0.5198\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5074 - val_loss: 0.5159\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5035 - val_loss: 0.5110\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4997 - val_loss: 0.5071\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4959 - val_loss: 0.5049\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4925 - val_loss: 0.4988\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4888 - val_loss: 0.4950\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4853 - val_loss: 0.4902\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4819 - val_loss: 0.4869\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4785 - val_loss: 0.4851\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4754 - val_loss: 0.4779\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4721 - val_loss: 0.4731\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4689 - val_loss: 0.4699\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4658 - val_loss: 0.4657\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4630 - val_loss: 0.4605\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4600 - val_loss: 0.4583\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4571 - val_loss: 0.4528\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4544 - val_loss: 0.4496\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4516 - val_loss: 0.4473\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4492 - val_loss: 0.4437\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4466 - val_loss: 0.4411\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4440 - val_loss: 0.4392\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4418 - val_loss: 0.4340\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4394 - val_loss: 0.4314\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4371 - val_loss: 0.4298\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4349 - val_loss: 0.4278\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4327 - val_loss: 0.4237\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4306 - val_loss: 0.4218\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4285 - val_loss: 0.4200\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4266 - val_loss: 0.4167\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4246 - val_loss: 0.4143\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4227 - val_loss: 0.4125\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4209 - val_loss: 0.4105\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4191 - val_loss: 0.4085\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4172 - val_loss: 0.4071\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4157 - val_loss: 0.4048\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4140 - val_loss: 0.4032\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4124 - val_loss: 0.4017\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.4002\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4094 - val_loss: 0.3986\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4079 - val_loss: 0.3973\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.3959\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.3949\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.3931\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4022 - val_loss: 0.3926\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4012 - val_loss: 0.3914\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3999 - val_loss: 0.3897\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3987 - val_loss: 0.3888\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3975 - val_loss: 0.3880\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3964 - val_loss: 0.3866\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3953 - val_loss: 0.3861\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3943 - val_loss: 0.3848\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3932 - val_loss: 0.3839\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3922 - val_loss: 0.3836\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3911 - val_loss: 0.3840\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3904 - val_loss: 0.3822\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3894 - val_loss: 0.3806\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3883 - val_loss: 0.3822\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3876 - val_loss: 0.3795\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3993\n",
      "[CV]  learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21, total= 1.0min\n",
      "[CV] learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21 ..\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5.0701 - val_loss: 2.9725\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.1451 - val_loss: 5.9015\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2758 - val_loss: 10.8119\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0903 - val_loss: 11.3108\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0053 - val_loss: 9.9424\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9444 - val_loss: 8.2069\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8977 - val_loss: 6.6004\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8609 - val_loss: 4.8507\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8311 - val_loss: 3.5263\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8061 - val_loss: 2.6353\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7845 - val_loss: 1.9734\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7657 - val_loss: 1.4481\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7491 - val_loss: 1.1077\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7340 - val_loss: 0.8819\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7201 - val_loss: 0.7221\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7071 - val_loss: 0.6649\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6951 - val_loss: 0.6775\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6837 - val_loss: 0.7491\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6729 - val_loss: 0.8815\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6627 - val_loss: 1.0684\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6528 - val_loss: 1.3065\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6436 - val_loss: 1.5427\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6350 - val_loss: 1.8315\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6268 - val_loss: 2.1426\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6190 - val_loss: 2.5085\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6115 - val_loss: 2.8640\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6770\n",
      "[CV]  learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21, total=  16.2s\n",
      "[CV] learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21 ..\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.4059 - val_loss: 3.5308\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.5613 - val_loss: 3.0045\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4038 - val_loss: 2.5464\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9815 - val_loss: 1.8717\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8396 - val_loss: 1.3067\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7692 - val_loss: 0.9966\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7270 - val_loss: 0.8331\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6993 - val_loss: 0.7309\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6799 - val_loss: 0.6922\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6652 - val_loss: 0.6623\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6528 - val_loss: 0.6391\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6420 - val_loss: 0.6199\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6325 - val_loss: 0.6066\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6235 - val_loss: 0.5952\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6150 - val_loss: 0.5855\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6070 - val_loss: 0.5761\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5992 - val_loss: 0.5671\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5915 - val_loss: 0.5590\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5841 - val_loss: 0.5515\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5769 - val_loss: 0.5445\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5697 - val_loss: 0.5376\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5627 - val_loss: 0.5308\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5559 - val_loss: 0.5241\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5491 - val_loss: 0.5179\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5425 - val_loss: 0.5114\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5360 - val_loss: 0.5049\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5296 - val_loss: 0.4989\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5234 - val_loss: 0.4930\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5173 - val_loss: 0.4880\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5115 - val_loss: 0.4819\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5058 - val_loss: 0.4768\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5003 - val_loss: 0.4726\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4951 - val_loss: 0.4680\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4901 - val_loss: 0.4648\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4854 - val_loss: 0.4611\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4809 - val_loss: 0.4579\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4767 - val_loss: 0.4552\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4727 - val_loss: 0.4523\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4688 - val_loss: 0.4503\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4651 - val_loss: 0.4481\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4616 - val_loss: 0.4479\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4584 - val_loss: 0.4464\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4552 - val_loss: 0.4442\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4524 - val_loss: 0.4442\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4495 - val_loss: 0.4436\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4469 - val_loss: 0.4428\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4444 - val_loss: 0.4427\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4420 - val_loss: 0.4431\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4397 - val_loss: 0.4436\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4375 - val_loss: 0.4441\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4353 - val_loss: 0.4441\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4335 - val_loss: 0.4456\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4315 - val_loss: 0.4460\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4297 - val_loss: 0.4467\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4278 - val_loss: 0.4484\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4262 - val_loss: 0.4489\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4247 - val_loss: 0.4493\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4256\n",
      "[CV]  learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21, total=  34.7s\n",
      "[CV] learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3002 - val_loss: 38.2652\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9964 - val_loss: 0.6706\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5490 - val_loss: 0.5520\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4986 - val_loss: 0.5090\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4710 - val_loss: 0.4813\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4526 - val_loss: 0.4761\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4406 - val_loss: 0.4565\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4321 - val_loss: 0.4533\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4259 - val_loss: 0.4502\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4210 - val_loss: 0.4389\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4166 - val_loss: 0.4360\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4123 - val_loss: 0.4313\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4086 - val_loss: 0.4253\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4064 - val_loss: 0.4228\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4030 - val_loss: 0.4209\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4011 - val_loss: 0.4192\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3986 - val_loss: 0.4156\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3966 - val_loss: 0.4137\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3949 - val_loss: 0.4128\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3936 - val_loss: 0.4104\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3928 - val_loss: 0.4101\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3908 - val_loss: 0.4070\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3898 - val_loss: 0.4080\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3892 - val_loss: 0.4037\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3878 - val_loss: 0.4030\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.4000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3864 - val_loss: 0.3972\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.3974\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3838 - val_loss: 0.3943\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3834 - val_loss: 0.3948\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3818 - val_loss: 0.3922\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3817 - val_loss: 0.3917\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3803 - val_loss: 0.3905\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3798 - val_loss: 0.3893\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3790 - val_loss: 0.3876\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3775 - val_loss: 0.3916\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3769 - val_loss: 0.3831\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3762 - val_loss: 0.3875\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3747 - val_loss: 0.3847\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3750 - val_loss: 0.3846\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3744 - val_loss: 0.3842\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.3814\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3735 - val_loss: 0.3808\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3718 - val_loss: 0.3834\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3725 - val_loss: 0.3804\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3704 - val_loss: 0.3824\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3703 - val_loss: 0.3798\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3705 - val_loss: 0.3800\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3686 - val_loss: 0.3783\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3686 - val_loss: 0.3797\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3683 - val_loss: 0.3820\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3675 - val_loss: 0.3765\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3672 - val_loss: 0.3772\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3667 - val_loss: 0.3766\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3656 - val_loss: 0.3773\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3663 - val_loss: 0.3754\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3650 - val_loss: 0.3750\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3645 - val_loss: 0.3750\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3633 - val_loss: 0.3766\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.3749\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3629 - val_loss: 0.3764\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3619 - val_loss: 0.3759\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3614 - val_loss: 0.3736\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3607 - val_loss: 0.3750\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3606 - val_loss: 0.3727\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3631 - val_loss: 0.3757\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3598 - val_loss: 0.3733\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3590 - val_loss: 0.3719\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3583 - val_loss: 0.3714\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3698\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3574 - val_loss: 0.3689\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3564 - val_loss: 0.3717\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3699\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3559 - val_loss: 0.3664\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3557 - val_loss: 0.3663\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3545 - val_loss: 0.3689\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3551 - val_loss: 0.3670\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3539 - val_loss: 0.3682\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3534 - val_loss: 0.3647\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3541 - val_loss: 0.3669\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3528 - val_loss: 0.3654\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3529 - val_loss: 0.3639\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3529 - val_loss: 0.3644\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3514 - val_loss: 0.3632\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3511 - val_loss: 0.3619\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3502 - val_loss: 0.3615\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3512 - val_loss: 0.3592\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3499 - val_loss: 0.3633\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3494 - val_loss: 0.3581\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3493 - val_loss: 0.3597\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3489 - val_loss: 0.3582\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3487 - val_loss: 0.3575\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3483 - val_loss: 0.3572\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3485 - val_loss: 0.3582\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3470 - val_loss: 0.3579\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.3626\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.3564\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3478 - val_loss: 0.3560\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3618\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3458 - val_loss: 0.3552\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3645\n",
      "[CV]  learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22, total=  56.2s\n",
      "[CV] learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2613 - val_loss: 0.6451\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5785 - val_loss: 0.8942\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5115 - val_loss: 1.2421\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4809 - val_loss: 1.2691\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4597 - val_loss: 0.9915\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4442 - val_loss: 0.6535\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4337 - val_loss: 0.5216\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4234 - val_loss: 0.4130\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4148 - val_loss: 0.3818\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4105 - val_loss: 0.4044\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4043 - val_loss: 0.4355\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3994 - val_loss: 0.4276\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3968 - val_loss: 0.4761\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3953 - val_loss: 0.5445\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3922 - val_loss: 0.5613\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3886 - val_loss: 0.6763\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3861 - val_loss: 0.6692\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3845 - val_loss: 0.7573\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3817 - val_loss: 0.6834\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3963\n",
      "[CV]  learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22, total=  10.9s\n",
      "[CV] learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2040 - val_loss: 71.0120\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0541 - val_loss: 42.2913\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8661 - val_loss: 1.3112\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5287 - val_loss: 0.5968\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4829 - val_loss: 0.4855\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4636 - val_loss: 0.4448\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4508 - val_loss: 0.4217\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4424 - val_loss: 0.4094\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4358 - val_loss: 0.4025\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4322 - val_loss: 0.3958\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4267 - val_loss: 0.3918\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4230 - val_loss: 0.3892\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4196 - val_loss: 0.3915\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.3996\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4136 - val_loss: 0.4076\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4108 - val_loss: 0.4218\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4081 - val_loss: 0.4317\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4068 - val_loss: 0.4354\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4048 - val_loss: 0.4429\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4034 - val_loss: 0.4453\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4021 - val_loss: 0.4460\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4001 - val_loss: 0.4415\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3947\n",
      "[CV]  learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22, total=  12.5s\n",
      "[CV] learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 7.7197 - val_loss: 43.0907\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.5377 - val_loss: 27.4372\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.0702 - val_loss: 17.4473\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.0672 - val_loss: 11.0914\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3745 - val_loss: 7.0664\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8936 - val_loss: 4.5088\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5544 - val_loss: 2.9277\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3139 - val_loss: 1.9631\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1426 - val_loss: 1.3974\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0191 - val_loss: 1.0599\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9292 - val_loss: 0.8770\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8636 - val_loss: 0.7898\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8150 - val_loss: 0.7557\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7787 - val_loss: 0.7567\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7515 - val_loss: 0.7696\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7308 - val_loss: 0.7947\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7148 - val_loss: 0.8231\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7022 - val_loss: 0.8540\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6920 - val_loss: 0.8834\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6838 - val_loss: 0.9089\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6772 - val_loss: 0.9189\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6713 - val_loss: 0.9382\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6664 - val_loss: 0.9536\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6673\n",
      "[CV]  learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49, total=  13.1s\n",
      "[CV] learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 7.6328 - val_loss: 25.5463\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.6957 - val_loss: 23.8232\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.3247 - val_loss: 22.6165\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.3439 - val_loss: 21.7670\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.6347 - val_loss: 21.1673\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1177 - val_loss: 20.7451\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7380 - val_loss: 20.4552\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4573 - val_loss: 20.2628\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2483 - val_loss: 20.1364\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0921 - val_loss: 20.0567\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9744 - val_loss: 20.0180\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8854 - val_loss: 20.0099\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8177 - val_loss: 20.0241\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7659 - val_loss: 20.0459\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7259 - val_loss: 20.0826\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6949 - val_loss: 20.1289\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6707 - val_loss: 20.1804\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6517 - val_loss: 20.2376\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6366 - val_loss: 20.3030\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6244 - val_loss: 20.3653\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6146 - val_loss: 20.4378\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6066 - val_loss: 20.5061\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0973\n",
      "[CV]  learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49, total=  12.0s\n",
      "[CV] learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 6.1564 - val_loss: 7.6683\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.4886 - val_loss: 4.9412\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.3699 - val_loss: 3.3299\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.6029 - val_loss: 2.3535\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.0673 - val_loss: 1.7864\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6878 - val_loss: 1.4390\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4151 - val_loss: 1.2303\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2174 - val_loss: 1.1115\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0734 - val_loss: 1.0396\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9677 - val_loss: 0.9896\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8894 - val_loss: 0.9739\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8312 - val_loss: 0.9570\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7875 - val_loss: 0.9426\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7545 - val_loss: 0.9414\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7294 - val_loss: 0.9351\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7100 - val_loss: 0.9457\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6951 - val_loss: 0.9437\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6832 - val_loss: 0.9404\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6737 - val_loss: 0.9554\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6661 - val_loss: 0.9559\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6596 - val_loss: 0.9558\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6543 - val_loss: 0.9576\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6496 - val_loss: 0.9476\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6455 - val_loss: 0.9447\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6419 - val_loss: 0.9405\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6455\n",
      "[CV]  learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49, total=  13.8s\n",
      "[CV] learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3724 - val_loss: 19.2760\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8289 - val_loss: 4.6055\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5845 - val_loss: 0.7004\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4829 - val_loss: 0.5034\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4459 - val_loss: 0.4495\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4238 - val_loss: 0.4262\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4095 - val_loss: 0.4112\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3994 - val_loss: 0.4155\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3919 - val_loss: 0.4120\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3855 - val_loss: 0.4010\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3805 - val_loss: 0.4074\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3762 - val_loss: 0.3889\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3711 - val_loss: 0.3859\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3705 - val_loss: 0.4045\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3652 - val_loss: 0.3846\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3648 - val_loss: 0.3959\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 0.4089\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3584 - val_loss: 0.3869\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.3860\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3541 - val_loss: 0.3805\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3534 - val_loss: 0.3894\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3503 - val_loss: 0.3799\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3493 - val_loss: 0.4104\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3492 - val_loss: 0.3684\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3456 - val_loss: 0.3799\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3455 - val_loss: 0.3619\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.3645\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3421 - val_loss: 0.3707\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3407 - val_loss: 0.3731\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3396 - val_loss: 0.3582\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3373 - val_loss: 0.3508\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3376 - val_loss: 0.3451\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3358 - val_loss: 0.3366\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3354 - val_loss: 0.3431\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3337 - val_loss: 0.3285\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3322 - val_loss: 0.3474\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3320 - val_loss: 0.3244\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3304 - val_loss: 0.3484\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3293 - val_loss: 0.3235\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3301 - val_loss: 0.3421\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3288 - val_loss: 0.3287\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3267 - val_loss: 0.3236\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3278 - val_loss: 0.3245\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3251 - val_loss: 0.3410\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3271 - val_loss: 0.3232\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3235 - val_loss: 0.3294\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3236 - val_loss: 0.3361\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3236 - val_loss: 0.3340\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3211 - val_loss: 0.3173\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3211 - val_loss: 0.3412\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3199 - val_loss: 0.3400\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3188 - val_loss: 0.3324\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3189 - val_loss: 0.3272\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3178 - val_loss: 0.3178\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3160 - val_loss: 0.3240\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3161 - val_loss: 0.3195\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3148 - val_loss: 0.3320\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3139 - val_loss: 0.3243\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3134 - val_loss: 0.3100\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3125 - val_loss: 0.3209\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3123 - val_loss: 0.3261\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3112 - val_loss: 0.3365\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3112 - val_loss: 0.3102\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3101 - val_loss: 0.3334\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3092 - val_loss: 0.3252\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3094 - val_loss: 0.3056\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3086 - val_loss: 0.3228\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3078 - val_loss: 0.3250\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3069 - val_loss: 0.3161\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3068 - val_loss: 0.3125\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3058 - val_loss: 0.3200\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3052 - val_loss: 0.3116\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3045 - val_loss: 0.3040\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3044 - val_loss: 0.3228\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3036 - val_loss: 0.3108\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3024 - val_loss: 0.3159\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3030 - val_loss: 0.3015\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3019 - val_loss: 0.3232\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3024 - val_loss: 0.3049\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3004 - val_loss: 0.3124\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2997 - val_loss: 0.3013\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2994 - val_loss: 0.3348\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2990 - val_loss: 0.2981\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2982 - val_loss: 0.3495\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2979 - val_loss: 0.2981\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2967 - val_loss: 0.3218\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2968 - val_loss: 0.3029\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2966 - val_loss: 0.3225\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2959 - val_loss: 0.2966\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2948 - val_loss: 0.3189\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2949 - val_loss: 0.2955\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2942 - val_loss: 0.3177\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2940 - val_loss: 0.2973\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2939 - val_loss: 0.2946\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2926 - val_loss: 0.3038\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2913 - val_loss: 0.2969\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2916 - val_loss: 0.3221\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2913 - val_loss: 0.2905\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2906 - val_loss: 0.3527\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2906 - val_loss: 0.2995\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3203\n",
      "[CV]  learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42, total=  58.3s\n",
      "[CV] learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2201 - val_loss: 0.8642\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6048 - val_loss: 0.7994\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5340 - val_loss: 1.0803\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4912 - val_loss: 1.1494\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4606 - val_loss: 0.9498\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4414 - val_loss: 0.6208\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4270 - val_loss: 0.4657\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4148 - val_loss: 0.3888\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4041 - val_loss: 0.4084\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3972 - val_loss: 0.4312\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3899 - val_loss: 0.5341\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3833 - val_loss: 0.6081\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3796 - val_loss: 0.7209\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3760 - val_loss: 0.8821\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3715 - val_loss: 0.9049\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3680 - val_loss: 0.9792\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.9532\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 1.0397\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3909\n",
      "[CV]  learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42, total=  10.9s\n",
      "[CV] learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1300 - val_loss: 2.2824\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6910 - val_loss: 2.5063\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5904 - val_loss: 1.3345\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5360 - val_loss: 1.8303\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4879 - val_loss: 1.1690\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4597 - val_loss: 1.0937\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4408 - val_loss: 0.5393\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4235 - val_loss: 0.5528\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4125 - val_loss: 0.4217\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4079 - val_loss: 0.3978\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3958 - val_loss: 0.7642\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3934 - val_loss: 0.3953\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3853 - val_loss: 0.3690\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3805 - val_loss: 0.6782\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3793 - val_loss: 0.5137\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3750 - val_loss: 1.5716\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3863 - val_loss: 1.5438\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3814 - val_loss: 2.5256\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3989 - val_loss: 1.2077\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3812 - val_loss: 0.8839\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3663 - val_loss: 0.3408\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3590 - val_loss: 0.3928\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3411\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.4823\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.3589\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.3810\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3504 - val_loss: 0.4593\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3500 - val_loss: 0.3360\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3499 - val_loss: 0.4983\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3480 - val_loss: 0.3747\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3470 - val_loss: 0.4128\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.5464\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3461 - val_loss: 0.3828\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3427 - val_loss: 0.5036\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3434 - val_loss: 0.3437\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.4820\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3404 - val_loss: 0.3595\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3414 - val_loss: 0.6282\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3388\n",
      "[CV]  learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42, total=  22.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 12.0min finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-d86e0cb35dad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[1;32m     16\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                   callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 736\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     81\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ff6dd618588>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sqry-VbMmtEB"
   },
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ghtQ2174mukj"
   },
   "outputs": [],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-JpwTtQmv-R"
   },
   "outputs": [],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rNPoFVMRmxQP"
   },
   "outputs": [],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qr3DHzRBmzdd"
   },
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Keras",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
